# taskmanagerplus-ai-analyzer (skeleton)

Base structure for analyzing automated test reports, **now enhanced with AI integration skeleton and working unit tests**.

---

## Objective

- Read reports (e.g., Playwright) generated by the `taskmanagerplus-tests` repository.  
- Normalize and summarize results using fixed, deterministic rules.  
- Format outputs as Markdown/JSON inside the `out/` folder.  
- (✅ Done) Implement and validate the deterministic flow with **Vitest**.  
- (✅ Done) Create the AI analyzer structure to support **root cause analysis** and **AI-generated insights**.

> Initially deterministic, now ready for optional AI integration in `src/analyzers/ai/` without changing the main workflow.

---

## 📂 Project Structure

```text
taskmanagerplus-ai-analyzer/
├─ out/
│  ├─ ai-analysis.json          # AI-generated insights (root cause, suggestions, etc.)
│  ├─ summary.json              # Summarized raw data output
│  └─ summary.md                # Human-readable markdown summary
├─ src/
│  ├─ analyzers/
│  │  ├─ ai/
│  │  │  ├─ prompts/
│  │  │  │  └─ rootCausePrompt.ts
│  │  │  ├─ providers/
│  │  │  │  ├─ base.ts
│  │  │  │  ├─ null.ts
│  │  │  │  └─ openai.ts
│  │  │  ├─ ai.types.ts
│  │  │  └─ aiAnalyzer.ts
│  │  └─ summaryAnalyzer.ts
│  ├─ formatters/
│  │  └─ markdownFormatter.ts
│  ├─ readers/
│  │  └─ playwrightReader.ts
│  ├─ types/
│  │  └─ playwright.ts
│  └─ main.ts
├─ tests/
│  ├─ ai/
│  │  └─ aiAnalyzer.test.ts
│  └─ unit/
│     ├─ summaryAnalyzer.test.ts
│     └─ markdownFormatter.test.ts
├─ package.json
├─ tsconfig.json
├─ vitest.config.ts
└─ README.md
```

---

## 🧪 What Has Been Implemented So Far

### ✅ 1. Deterministic Flow (Item 1 completed)

- Core logic for reading Playwright reports (`playwrightReader.ts`).
- Analysis layer (`summaryAnalyzer.ts`) summarizes the results in a fixed, predictable way.
- Formatting layer (`markdownFormatter.ts`) converts the summaries into Markdown and JSON.
- Output automatically stored in `out/summary.json` and `out/summary.md`.

### ✅ 2. Unit Tests with Vitest

- Full test setup using **Vitest**, confirming that the deterministic flow works end to end.
- Test files created under `tests/unit/`:
  - `summaryAnalyzer.test.ts`
  - `markdownFormatter.test.ts`
- Tests validate structure, consistency, and expected output.
- Scripts `npm test` and `npm run dev` confirmed functional.

### ✅ 3. AI Integration Skeleton (Item 2 completed)

- Added a new directory `src/analyzers/ai` for modular AI support.  
- Created base provider architecture:
  - `base.ts`: abstract provider definition.
  - `openai.ts`: handles communication with OpenAI API.
  - `null.ts`: fallback provider for offline testing.
- Implemented prompt definition (`rootCausePrompt.ts`) with the first version of the **root cause analysis prompt**.
- Created `aiAnalyzer.ts` to orchestrate:
  - Test summary interpretation.
  - Prompt construction and provider interaction.
  - Output generation into `out/ai-analysis.json`.

### ✅ 4. Latest Change — Consume **Real** Playwright Reports (Item 3 completed)

- The reader (`src/readers/playwrightReader.ts`) now supports the **modern Playwright JSON** format:  
  `suites → specs → tests → results` (while keeping backward compatibility with legacy array/top-level `tests`).  
- Status mapping is deterministic: `timedOut` / `interrupted` are treated as `failed` to keep totals consistent.
- Each test case is guaranteed to have a **stable string `id`** (prevents type issues downstream).
- No changes were required to `summaryAnalyzer`, `markdownFormatter`, or the AI interfaces.

**Result:** end-to-end run generates all three outputs successfully:
- `out/summary.json`
- `out/summary.md`
- `out/ai-analysis.json`

---

## How to use (after logic is implemented)

1. **Install dependencies:**
   ```bash
   npm install
   ```

2. **Run unit tests (Vitest):**
   ```bash
   npm test
   ```

3. **Run in development mode (ts-node):**
   ```bash
   npm run dev -- ./path/to/playwright-report.json
   ```

4. **Build and run compiled version:**
   ```bash
   npm run build
   npm start -- ./path/to/playwright-report.json
   ```


> Example below uses Windows PowerShell paths. Adjust the report path if needed.

5) **Clean previous build (optional):**
```powershell
Remove-Item -Recurse -Force .\dist\ 2>$null
```

6) **Build TypeScript:**
```powershell
npm run build
```

7) **Run the analyzer with your real Playwright report:**
```powershell
node dist/main.js "C:\Desenvolvimento\workspace\taskmanagerplus-tests\ui-tests\reports\ui\playwright-report.json"
```

Outputs will be created in `out/`:
- `out/summary.json`
- `out/summary.md`
- `out/ai-analysis.json`

> Tip: you can add an npm script alias for a shorter command if you run this often.

---

## Notes

- All code comments are in **English**.  
- The project now includes both **deterministic** and **AI-ready** analysis flows.  
- The `out/` folder is automatically populated with results after execution.  
- Vitest is used for all testing to ensure reliability and coverage.  
- The AI integration remains **optional** and does not affect the core deterministic pipeline.

---

## Project Overview and Purpose

The **TaskManagerPlus AI Analyzer** project is a solid foundation designed to gradually evolve into an intelligent tool for analyzing automated test reports.

At this stage, the project already:
- Reads test reports (such as those generated by Playwright);
- Summarizes the results deterministically;
- Formats outputs as both JSON and Markdown;
- Supports an optional AI pipeline capable of root-cause reasoning and report enrichment.

This ensures **stability**, **transparency**, and **predictability** in the base flow — while opening the path to **intelligent analysis** powered by AI.

---

## Modular Architecture

The project follows a **clean modular architecture**, where each part is independent and replaceable:

| Layer | Responsibility |
|-------|----------------|
| **readers** | Read and normalize external reports (Playwright, future sources). |
| **analyzers** | Generate summaries, deterministic or AI-based. |
| **formatters** | Output Markdown/JSON summaries for human or automated consumption. |
| **ai/providers** | Encapsulate external AI providers such as OpenAI. |
| **ai/prompts** | Define structured prompts for reasoning and suggestions. |

---

### Why integrate AI?

Artificial intelligence brings a new dimension to test result interpretation.  
While deterministic code handles *what happened*, AI will help understand *why it happened* and *what to test next*.

The AI layer aims to:
- **Detect failure patterns** (recurring issues, flaky tests, environment mismatches).  
- **Provide root-cause insights** with contextual explanations.  
- **Recommend new test cases** for uncovered scenarios.  
- **Highlight priorities** based on severity and frequency.  
- **Learn over time**, improving its understanding of project stability.

---

### Why this approach matters

1. **Gradual evolution:** starts stable and deterministic, expands intelligently.  
2. **Transparency:** deterministic logic ensures clarity before AI inference.  
3. **Flexibility:** new readers or providers can be added without changing the core.  
4. **Future-ready:** the architecture anticipates long-term integration with AI ecosystems.  
5. **Continuous learning:** every iteration builds toward autonomous quality analysis.

---

## In Summary

The **TaskManagerPlus AI Analyzer** represents the transition from **manual interpretation** of test reports to **AI-assisted QA intelligence**.

It’s not only a tool to read and summarize test results —  
it’s a foundation for transforming raw test data into **actionable knowledge**, helping teams understand what is happening, why it happens, and how to improve.

> 💡 “From deterministic reporting to intelligent quality insights — one step at a time.”





