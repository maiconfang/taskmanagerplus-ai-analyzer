# taskmanagerplus-ai-analyzer (skeleton)

Base structure for analyzing automated test reports **without AI integration yet**.

## Objective
- Read reports (e.g., Playwright) generated by the `taskmanagerplus-tests` repository.
- Normalize and summarize results using fixed, deterministic rules.
- Format outputs as Markdown/JSON inside the `out/` folder.

> Future: optional AI integration in `src/analyzers/`, without changing the main workflow.

## Structure
```text
taskmanagerplus-ai-analyzer/
├─ src/
│  ├─ readers/
│  │  └─ playwrightReader.ts
│  ├─ analyzers/
│  │  └─ summaryAnalyzer.ts
│  ├─ formatters/
│  │  └─ markdownFormatter.ts
│  ├─ types/
│  │  └─ playwright.ts
│  └─ main.ts
├─ out/                  # generated outputs (json/md)
├─ package.json
├─ tsconfig.json
└─ README.md
```

## How to use (after logic is implemented)
1. Install dependencies:
   ```bash
   npm install
   ```
2. Run in development mode (ts-node):
   ```bash
   npm run dev -- ./path/to/playwright-report.json
   ```
3. Build and run compiled version:
   ```bash
   npm run build
   npm start -- ./path/to/playwright-report.json
   ```

## Notes
- All code comments are in **English**.
- **No AI** integration at this stage.
- The `out/` folder is empty by default.

## Project overview and purpose

The **TaskManagerPlus AI Analyzer** project is a solid foundation designed to gradually evolve into an intelligent tool for analyzing automated test reports.

At this stage, the project works in a fully deterministic way: it reads test reports (such as those generated by Playwright), summarizes the results, and formats the outputs in a structured way without using artificial intelligence. This ensures stability, transparency, and predictable results while creating a clear flow between data reading, analysis, and formatting.

The main idea is to build a **modular and extensible architecture**, where each part of the process is independent:
- **readers** handle reading and normalizing reports;
- **analyzers** process and summarize information;
- **formatters** generate human-readable outputs such as Markdown and JSON.

This organization makes it easier to integrate **AI** in the future as an optional layer, without needing to modify the system core.

### Why integrate AI in the future?

Artificial intelligence will bring a new layer of insight to the test results.  
While the current code summarizes numbers and statuses, AI will be able to:

- **Detect failure patterns** (e.g., recurring errors in the same component or environment);
- **Generate explanations** about likely causes (root cause analysis);
- **Suggest new test cases** based on detected gaps;
- **Prioritize failures** according to their impact and frequency;
- **Learn from past results** to anticipate risks and instabilities.

With this, the project will evolve from being just a “test summary” to becoming a **decision-support tool for QA**, helping testers and engineers understand what is happening, why it is happening, and what can be improved.

### Why is this approach beneficial?

1. **Natural evolution:** starts simple and solid, and grows smarter over time.  
2. **Full control:** before introducing AI, you fully understand how the system behaves.  
3. **Extensibility:** the modular structure allows adding new analyzers, readers, and formatters easily.  
4. **Future-proof:** AI integration will be just another layer in `analyzers/`, without breaking existing code.  
5. **Continuous learning:** each step built today paves the way for a tool that learns from test results and generates real insights.

In summary, the **TaskManagerPlus AI Analyzer** represents the first step toward transforming technical test reports into intelligent knowledge, making the QA process more predictive, strategic, and efficient.
